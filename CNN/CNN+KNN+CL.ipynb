{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in /root/miniconda3/lib/python3.8/site-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: gensim in /root/miniconda3/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (1.10.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nltk in /root/miniconda3/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /root/miniconda3/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /root/miniconda3/lib/python3.8/site-packages (from nltk) (2023.10.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (1.24.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (4.35.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: keras in /root/miniconda3/lib/python3.8/site-packages (2.13.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: faiss-gpu in /root/miniconda3/lib/python3.8/site-packages (1.7.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tensorflow in /root/miniconda3/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.24.2)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.51.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (4.22.1)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/miniconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /root/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /root/miniconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /root/miniconda3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install transformers\n",
    "\n",
    "!pip install keras\n",
    "!pip install faiss-gpu\n",
    "\n",
    "!pip install tensorflow\n",
    "import keras\n",
    "import tensorflow\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "# from torch.optim import AdamW\n",
    "from transformers import BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KDTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>astro-ph.CO</th>\n",
       "      <th>astro-ph.EP</th>\n",
       "      <th>astro-ph.GA</th>\n",
       "      <th>astro-ph.HE</th>\n",
       "      <th>astro-ph.IM</th>\n",
       "      <th>astro-ph.SR</th>\n",
       "      <th>cond-mat.dis-nn</th>\n",
       "      <th>cond-mat.mes-hall</th>\n",
       "      <th>...</th>\n",
       "      <th>q-fin.RM</th>\n",
       "      <th>q-fin.ST</th>\n",
       "      <th>q-fin.TR</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>stat.AP</th>\n",
       "      <th>stat.CO</th>\n",
       "      <th>stat.ME</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat.OT</th>\n",
       "      <th>stat.TH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many firms days opting specialize rather gener...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper analyses changes public opinion tracking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>randomaccess networks ieee 80211 network diffe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mimo wireless channel offers rich ground quali...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article presents new search algorithm nphard p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alice seeks informationtheoretically secure so...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>algorithms generate various combinatorial stru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>describe fast method eliminate features variab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>consider twouser gaussian multiple access chan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paper propose robust transceiver design kpair ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  astro-ph  astro-ph.CO  \\\n",
       "0  many firms days opting specialize rather gener...         0            0   \n",
       "1  paper analyses changes public opinion tracking...         0            0   \n",
       "2  randomaccess networks ieee 80211 network diffe...         0            0   \n",
       "3  mimo wireless channel offers rich ground quali...         0            0   \n",
       "4  article presents new search algorithm nphard p...         0            0   \n",
       "5  alice seeks informationtheoretically secure so...         0            0   \n",
       "6  algorithms generate various combinatorial stru...         0            0   \n",
       "7  describe fast method eliminate features variab...         0            0   \n",
       "8  consider twouser gaussian multiple access chan...         0            0   \n",
       "9  paper propose robust transceiver design kpair ...         0            0   \n",
       "\n",
       "   astro-ph.EP  astro-ph.GA  astro-ph.HE  astro-ph.IM  astro-ph.SR  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "5            0            0            0            0            0   \n",
       "6            0            0            0            0            0   \n",
       "7            0            0            0            0            0   \n",
       "8            0            0            0            0            0   \n",
       "9            0            0            0            0            0   \n",
       "\n",
       "   cond-mat.dis-nn  cond-mat.mes-hall  ...  q-fin.RM  q-fin.ST  q-fin.TR  \\\n",
       "0                0                  0  ...         0         0         0   \n",
       "1                0                  0  ...         0         0         0   \n",
       "2                0                  0  ...         0         0         0   \n",
       "3                0                  0  ...         0         0         0   \n",
       "4                0                  0  ...         0         0         0   \n",
       "5                0                  0  ...         0         0         0   \n",
       "6                0                  0  ...         0         0         0   \n",
       "7                0                  0  ...         0         0         0   \n",
       "8                0                  0  ...         0         0         0   \n",
       "9                0                  0  ...         0         0         0   \n",
       "\n",
       "   quant-ph  stat.AP  stat.CO  stat.ME  stat.ML  stat.OT  stat.TH  \n",
       "0         0        0        0        0        0        0        0  \n",
       "1         0        0        0        0        0        0        0  \n",
       "2         0        0        0        0        0        0        0  \n",
       "3         0        0        0        0        0        0        0  \n",
       "4         0        0        0        0        0        0        0  \n",
       "5         0        0        0        0        0        0        0  \n",
       "6         0        0        0        0        0        0        0  \n",
       "7         0        0        0        0        0        0        0  \n",
       "8         0        0        0        0        0        0        0  \n",
       "9         0        0        0        0        0        0        0  \n",
       "\n",
       "[10 rows x 146 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./df1.csv', nrows=10000)\n",
    "df1['abstract'] = df1['abstract'].astype(str)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载Word2Vec模型\n",
    "model_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 确保这是你的nltk_data目录所在的路径\n",
    "nltk_data_path = 'autodl-fs/nltk_data2'\n",
    "\n",
    "# 添加到NLTK的数据路径\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "\n",
    "print(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 分词和预处理函数\n",
    "def tokenize_and_process(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    words = [word.lower() for word in words]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "# 对DataFrame中的abstract列进行分词和预处理\n",
    "df1['tokenized_abstract'] = df1['abstract'].apply(tokenize_and_process)\n",
    "\n",
    "# 函数来将单词转换为Word2Vec向量，如果模型中没有该词，则使用UNK向量\n",
    "def word_to_vec(word, model):\n",
    "    return model[word] if word in model.key_to_index else model['UNK']\n",
    "\n",
    "# 函数来将句子的分词列表转换为Word2Vec向量列表\n",
    "def tokens_to_vectors(tokens, model):\n",
    "    return [word_to_vec(token, model) for token in tokens]\n",
    "\n",
    "# 应用函数将tokenized_abstract列的分词列表转换为Word2Vec向量列表\n",
    "df1['word_vectors'] = df1['tokenized_abstract'].apply(lambda tokens: tokens_to_vectors(tokens, word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((8000, 217, 300), (8000, 145))\n",
      "Test set shape: ((2000, 217, 300), (2000, 145))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 找出word_vectors中最长的长度\n",
    "MAX_SEQUENCE_LENGTH = df1['word_vectors'].apply(len).max()\n",
    "UNK_VECTOR = word2vec_model['UNK']  # 获取'UNK'的向量表示\n",
    "# 使用这个长度作为填充或截断的基础\n",
    "def pad_or_truncate_vectors(word_vectors, max_length, unk_vector):\n",
    "    \"\"\"\n",
    "    如果word_vectors长度小于max_length，则用unk_vector填充；\n",
    "    如果word_vectors长度大于max_length，则截断。\n",
    "    \"\"\"\n",
    "    # 获取当前word vectors的长度\n",
    "    sequence_length = len(word_vectors)\n",
    "    \n",
    "    # 如果当前长度小于最大长度，进行填充\n",
    "    if sequence_length < max_length:\n",
    "        padding = [unk_vector] * (max_length - sequence_length)\n",
    "        word_vectors.extend(padding)\n",
    "    # 如果当前长度大于最大长度，进行截断\n",
    "    elif sequence_length > max_length:\n",
    "        word_vectors = word_vectors[:max_length]\n",
    "    \n",
    "    return word_vectors\n",
    "\n",
    "# 应用函数pad_or_truncate_vectors到每一行的word_vectors列\n",
    "df1['padded_word_vectors'] = df1['word_vectors'].apply(\n",
    "    lambda x: pad_or_truncate_vectors(x, MAX_SEQUENCE_LENGTH, UNK_VECTOR))\n",
    "\n",
    "# 检查结果\n",
    "df1['padded_word_vectors'].apply(len)  # 每个向量的长度都应该是MAX_SEQUENCE_LENGTH\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 准备特征：将padded_word_vectors的列表转换为NumPy数组\n",
    "X = np.array(df1['padded_word_vectors'].tolist())\n",
    "\n",
    "# 准备标签：获取所有标签列\n",
    "label_columns = df1.columns.difference(['abstract', 'tokenized_abstract', 'word_vectors', 'padded_word_vectors'])\n",
    "y = df1[label_columns].values\n",
    "\n",
    "# 分割数据集为训练集和测试集，这里使用20%的数据作为测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出分割后的数据集维度，仅用于确认 \n",
    "print(f'Training set shape: {X_train.shape, y_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape, y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((8000, 217, 300), (8000, 145))\n",
      "Test set shape: ((2000, 217, 300), (2000, 145))\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set shape: {X_train.shape, y_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape, y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "225/225 [==============================] - 2s 5ms/step - loss: 0.0941 - output_loss: 0.0941 - output_micro_f1: 0.1240 - val_loss: 0.0565 - val_output_loss: 0.0565 - val_output_micro_f1: 0.2320\n",
      "Epoch 2/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0553 - output_loss: 0.0553 - output_micro_f1: 0.2821 - val_loss: 0.0499 - val_output_loss: 0.0499 - val_output_micro_f1: 0.3336\n",
      "Epoch 3/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0504 - output_loss: 0.0504 - output_micro_f1: 0.3714 - val_loss: 0.0466 - val_output_loss: 0.0466 - val_output_micro_f1: 0.3944\n",
      "Epoch 4/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0470 - output_loss: 0.0470 - output_micro_f1: 0.4258 - val_loss: 0.0431 - val_output_loss: 0.0431 - val_output_micro_f1: 0.4515\n",
      "Epoch 5/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0442 - output_loss: 0.0442 - output_micro_f1: 0.4627 - val_loss: 0.0415 - val_output_loss: 0.0415 - val_output_micro_f1: 0.4885\n",
      "Epoch 6/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0419 - output_loss: 0.0419 - output_micro_f1: 0.4932 - val_loss: 0.0393 - val_output_loss: 0.0393 - val_output_micro_f1: 0.4978\n",
      "Epoch 7/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0402 - output_loss: 0.0402 - output_micro_f1: 0.5149 - val_loss: 0.0386 - val_output_loss: 0.0386 - val_output_micro_f1: 0.5189\n",
      "Epoch 8/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0385 - output_loss: 0.0385 - output_micro_f1: 0.5276 - val_loss: 0.0372 - val_output_loss: 0.0372 - val_output_micro_f1: 0.5274\n",
      "Epoch 9/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0372 - output_loss: 0.0372 - output_micro_f1: 0.5506 - val_loss: 0.0372 - val_output_loss: 0.0372 - val_output_micro_f1: 0.5373\n",
      "Epoch 10/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0355 - output_loss: 0.0355 - output_micro_f1: 0.5623 - val_loss: 0.0358 - val_output_loss: 0.0358 - val_output_micro_f1: 0.5464\n",
      "Epoch 11/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0345 - output_loss: 0.0345 - output_micro_f1: 0.5779 - val_loss: 0.0358 - val_output_loss: 0.0358 - val_output_micro_f1: 0.5542\n",
      "Epoch 12/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0332 - output_loss: 0.0332 - output_micro_f1: 0.5919 - val_loss: 0.0352 - val_output_loss: 0.0352 - val_output_micro_f1: 0.5590\n",
      "Epoch 13/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0323 - output_loss: 0.0323 - output_micro_f1: 0.6034 - val_loss: 0.0356 - val_output_loss: 0.0356 - val_output_micro_f1: 0.5559\n",
      "Epoch 14/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0312 - output_loss: 0.0312 - output_micro_f1: 0.6158 - val_loss: 0.0347 - val_output_loss: 0.0347 - val_output_micro_f1: 0.5577\n",
      "Epoch 15/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0309 - output_loss: 0.0309 - output_micro_f1: 0.6186 - val_loss: 0.0346 - val_output_loss: 0.0346 - val_output_micro_f1: 0.5606\n",
      "Epoch 16/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0298 - output_loss: 0.0298 - output_micro_f1: 0.6269 - val_loss: 0.0343 - val_output_loss: 0.0343 - val_output_micro_f1: 0.5627\n",
      "Epoch 17/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0293 - output_loss: 0.0293 - output_micro_f1: 0.6376 - val_loss: 0.0343 - val_output_loss: 0.0343 - val_output_micro_f1: 0.5724\n",
      "Epoch 18/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0287 - output_loss: 0.0287 - output_micro_f1: 0.6475 - val_loss: 0.0342 - val_output_loss: 0.0342 - val_output_micro_f1: 0.5716\n",
      "Epoch 19/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0280 - output_loss: 0.0280 - output_micro_f1: 0.6534 - val_loss: 0.0344 - val_output_loss: 0.0344 - val_output_micro_f1: 0.5737\n",
      "Epoch 20/40\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 0.0273 - output_loss: 0.0273 - output_micro_f1: 0.6596 - val_loss: 0.0342 - val_output_loss: 0.0342 - val_output_micro_f1: 0.5679\n",
      "Epoch 21/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0269 - output_loss: 0.0269 - output_micro_f1: 0.6633 - val_loss: 0.0345 - val_output_loss: 0.0345 - val_output_micro_f1: 0.5734\n",
      "Epoch 22/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0261 - output_loss: 0.0261 - output_micro_f1: 0.6736 - val_loss: 0.0344 - val_output_loss: 0.0344 - val_output_micro_f1: 0.5723\n",
      "Epoch 23/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0257 - output_loss: 0.0257 - output_micro_f1: 0.6813 - val_loss: 0.0343 - val_output_loss: 0.0343 - val_output_micro_f1: 0.5684\n",
      "Epoch 24/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0254 - output_loss: 0.0254 - output_micro_f1: 0.6823 - val_loss: 0.0345 - val_output_loss: 0.0345 - val_output_micro_f1: 0.5590\n",
      "Epoch 25/40\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0251 - output_loss: 0.0251 - output_micro_f1: 0.6868 - val_loss: 0.0351 - val_output_loss: 0.0351 - val_output_micro_f1: 0.5642\n",
      "Epoch 26/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0245 - output_loss: 0.0245 - output_micro_f1: 0.6931 - val_loss: 0.0349 - val_output_loss: 0.0349 - val_output_micro_f1: 0.5690\n",
      "Epoch 27/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0241 - output_loss: 0.0241 - output_micro_f1: 0.6981 - val_loss: 0.0347 - val_output_loss: 0.0347 - val_output_micro_f1: 0.5706\n",
      "Epoch 28/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0240 - output_loss: 0.0240 - output_micro_f1: 0.6996 - val_loss: 0.0351 - val_output_loss: 0.0351 - val_output_micro_f1: 0.5674\n",
      "Epoch 29/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0234 - output_loss: 0.0234 - output_micro_f1: 0.7066 - val_loss: 0.0354 - val_output_loss: 0.0354 - val_output_micro_f1: 0.5632\n",
      "Epoch 30/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0229 - output_loss: 0.0229 - output_micro_f1: 0.7114 - val_loss: 0.0355 - val_output_loss: 0.0355 - val_output_micro_f1: 0.5623\n",
      "Epoch 31/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0222 - output_loss: 0.0222 - output_micro_f1: 0.7197 - val_loss: 0.0361 - val_output_loss: 0.0361 - val_output_micro_f1: 0.5603\n",
      "Epoch 32/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0222 - output_loss: 0.0222 - output_micro_f1: 0.7209 - val_loss: 0.0361 - val_output_loss: 0.0361 - val_output_micro_f1: 0.5593\n",
      "Epoch 33/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0221 - output_loss: 0.0221 - output_micro_f1: 0.7183 - val_loss: 0.0365 - val_output_loss: 0.0365 - val_output_micro_f1: 0.5551\n",
      "Epoch 34/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0219 - output_loss: 0.0219 - output_micro_f1: 0.7254 - val_loss: 0.0356 - val_output_loss: 0.0356 - val_output_micro_f1: 0.5635\n",
      "Epoch 35/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0214 - output_loss: 0.0214 - output_micro_f1: 0.7312 - val_loss: 0.0361 - val_output_loss: 0.0361 - val_output_micro_f1: 0.5616\n",
      "Epoch 36/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0215 - output_loss: 0.0215 - output_micro_f1: 0.7284 - val_loss: 0.0363 - val_output_loss: 0.0363 - val_output_micro_f1: 0.5708\n",
      "Epoch 37/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0212 - output_loss: 0.0212 - output_micro_f1: 0.7352 - val_loss: 0.0365 - val_output_loss: 0.0365 - val_output_micro_f1: 0.5548\n",
      "Epoch 38/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0210 - output_loss: 0.0210 - output_micro_f1: 0.7334 - val_loss: 0.0367 - val_output_loss: 0.0367 - val_output_micro_f1: 0.5559\n",
      "Epoch 39/40\n",
      "225/225 [==============================] - 1s 4ms/step - loss: 0.0206 - output_loss: 0.0206 - output_micro_f1: 0.7400 - val_loss: 0.0370 - val_output_loss: 0.0370 - val_output_micro_f1: 0.5669\n",
      "Epoch 40/40\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.0203 - output_loss: 0.0203 - output_micro_f1: 0.7412 - val_loss: 0.0368 - val_output_loss: 0.0368 - val_output_micro_f1: 0.5628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa3eddb5850>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Layer\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "def micro_f1(y_true, y_pred):\n",
    "    # 预测值大于0.3的被认为是正类\n",
    "    y_pred = K.cast(K.greater(y_pred, 0.3), K.floatx())\n",
    "    \n",
    "    # 计算真正例、假正例和假负例\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=0)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)\n",
    "    \n",
    "    # 计算精确度和召回率\n",
    "    precision = K.sum(true_positives) / (K.sum(predicted_positives) + K.epsilon())\n",
    "    recall = K.sum(true_positives) / (K.sum(possible_positives) + K.epsilon())\n",
    "    \n",
    "    # 计算micro-F1分数\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "# 模型参数\n",
    "max_sequence_length = 217  # 句子的最大长度\n",
    "embedding_dim = 300  # 词嵌入的维度\n",
    "num_labels = 145  # 标签的数量\n",
    "\n",
    "\n",
    "# 模型输入和结构定义\n",
    "input_ = Input(shape=(max_sequence_length, embedding_dim),name='input_')\n",
    "\n",
    "# 可以通过交叉验证调整filters和kernel_size\n",
    "conv = Conv1D(filters=128, kernel_size=3, activation='relu')(input_)\n",
    "gmp = GlobalMaxPooling1D(name='gmp')(conv)\n",
    "dropout = Dropout(0.5)(gmp)\n",
    "# 可以通过交叉验证调整units\n",
    "dense = Dense(128, activation='relu')(dropout)\n",
    "output = Dense(num_labels, activation='sigmoid', name='output')(dense)\n",
    "\n",
    "\n",
    "# 真实标签的输入\n",
    "y_true_input = Input(shape=(num_labels,), name='y_true_input')\n",
    "\n",
    "# 创建模型实例\n",
    "model = Model(inputs=input_, outputs=output)\n",
    "def contrastive_loss_function(y_true, features, tau_prime):\n",
    "    # 计算标签相似度矩阵\n",
    "    label_similarities = tf.matmul(y_true, y_true, transpose_b=True)\n",
    "    \n",
    "    # 动态系数归一化\n",
    "    beta = label_similarities / tf.reduce_sum(label_similarities, axis=1, keepdims=True)\n",
    "    \n",
    "    # 特征标准化\n",
    "    features_norm = tf.nn.l2_normalize(features, axis=1)\n",
    "    \n",
    "    # 计算特征间的成对欧式距离\n",
    "    pairwise_distances = tf.norm(tf.expand_dims(features_norm, 1) - tf.expand_dims(features_norm, 0), axis=2)\n",
    "    \n",
    "    # 对比损失计算\n",
    "    L_con = -beta * tf.math.reduce_logsumexp(-pairwise_distances / tau_prime, axis=1)\n",
    "    \n",
    "    # 将对比损失加和\n",
    "    contrastive_loss = tf.reduce_sum(L_con)\n",
    "    \n",
    "    return contrastive_loss\n",
    "\n",
    "# 自定义层以计算对比损失\n",
    "class ContrastiveLossLayer(Layer):\n",
    "    def __init__(self, gamma=0.5, tau_prime=10, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma      # 对比损失的权重参数\n",
    "        self.tau_prime = tau_prime  # 温度参数\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_true, features = inputs\n",
    "        # 计算对比损失，传入温度参数 tau_prime\n",
    "        loss = contrastive_loss_function(y_true, features, self.tau_prime)\n",
    "        # 应用权重 gamma\n",
    "        self.add_loss(loss * self.gamma)\n",
    "        # 返回与 features 形状相同的零张量\n",
    "        return tf.zeros_like(features)\n",
    "\n",
    "\n",
    "# 实例化对比损失层并设置gamma值\n",
    "contrastive_loss_layer = ContrastiveLossLayer(gamma=0.5, name='contrastive_loss')\n",
    "\n",
    "# 获取gmp层的输出用于对比损失计算\n",
    "gmp_output = model.get_layer('gmp').output\n",
    "\n",
    "# 调用对比损失层，并将真实标签和gmp层的输出传入\n",
    "contrastive_loss_layer([y_true_input, gmp_output])\n",
    "model = Model(inputs=[input_, y_true_input], outputs=[output,gmp])\n",
    "\n",
    "\n",
    "# 编译模型时，只需要指定主输出的损失函数\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'output': 'binary_crossentropy', 'gmp': None},\n",
    "              metrics={'output': micro_f1})\n",
    "\n",
    "# 训练模型时的输入：特征和真实标签\n",
    "model.fit([X_train, y_train],\n",
    "          {'output': y_train},\n",
    "          batch_size=32,\n",
    "          epochs=40,\n",
    "          validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.0381 - output_loss: 0.0381 - output_micro_f1: 0.5736\n",
      "Test loss (overall): 0.038086581975221634\n",
      "Test loss (main output): 0.038086581975221634\n",
      "Test micro-F1 score (main output): 0.5736383199691772\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估模型性能\n",
    "evaluation_results = model.evaluate([X_test,y_test], y_test)\n",
    "\n",
    "# evaluation_results[0] 是整体的损失值\n",
    "# evaluation_results[1] 是主输出层的损失值\n",
    "# evaluation_results[2] 是主输出层的micro-F1分数\n",
    "\n",
    "# 打印测试集上的性能\n",
    "print(f'Test loss (overall): {evaluation_results[0]}')\n",
    "print(f'Test loss (main output): {evaluation_results[1]}')\n",
    "print(f'Test micro-F1 score (main output): {evaluation_results[2]}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step\n",
      "63/63 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the training set using the trained model\n",
    "# This will be used for constructing the datastore for k-NN\n",
    "train_features = model.predict([X_train,y_train])[1]\n",
    "from sklearn.neighbors import NearestNeighbors  # 这里导入NearestNeighbors\n",
    "\n",
    "# Construct the datastore for k-NN using the extracted features and the known labels\n",
    "datastore = NearestNeighbors(n_neighbors=5).fit(train_features)\n",
    "\n",
    "# Define k-NN inference function\n",
    "def knn_inference(model, datastore, x_test, k=3, temperature=0.5, lambda_factor=0.8):\n",
    "    cnn_test_predictions, test_features = model.predict(x_test)\n",
    "    \n",
    "    knn_test_predictions = np.zeros(cnn_test_predictions.shape)\n",
    "    \n",
    "    for i, feature in enumerate(test_features):\n",
    "        distances, indices = datastore.kneighbors([feature], n_neighbors=k)\n",
    "        weights = np.exp(-np.array(distances) / temperature)\n",
    "        weights = weights / np.sum(weights)\n",
    "        \n",
    "        for idx, w in zip(indices[0], weights[0]):\n",
    "            knn_test_predictions[i] += w * y_train[idx]\n",
    "    \n",
    "    knn_test_predictions /= np.max(knn_test_predictions, axis=1, keepdims=True)\n",
    "    \n",
    "    # Combine CNN model's output with k-NN's prediction to get the final prediction\n",
    "    final_predictions = lambda_factor * cnn_test_predictions + (1 - lambda_factor) * knn_test_predictions\n",
    "    return final_predictions\n",
    "\n",
    "# Perform inference with k-NN on the test set\n",
    "final_predictions = knn_inference(model, datastore, [X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-F1 score for final predictions: 0.5771780853786205\n",
      "Test mean squared error: 0.008857158934618355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "\n",
    "# 定义阈值\n",
    "threshold = 0.3\n",
    "\n",
    "# 将概率转换为二进制标签\n",
    "y_pred_binary = (final_predictions >= threshold).astype(int)\n",
    "\n",
    "# 计算micro-F1分数\n",
    "micro_f1_score = f1_score(y_test, y_pred_binary, average='micro')\n",
    "\n",
    "# 打印micro-F1分数\n",
    "print(f'Micro-F1 score for final predictions: {micro_f1_score}')\n",
    "\n",
    "# 计算测试误差（均方误差）\n",
    "test_error = mean_squared_error(y_test, final_predictions)\n",
    "\n",
    "# 打印测试误差\n",
    "print(f'Test mean squared error: {test_error}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
