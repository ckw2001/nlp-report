{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: torch in /root/miniconda3/lib/python3.8/site-packages (2.0.0+cu118)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.8/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/lib/python3.8/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/lib/python3.8/site-packages (from triton==2.0.0->torch) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: gensim in /root/miniconda3/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /root/miniconda3/lib/python3.8/site-packages (from gensim) (6.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: nltk in /root/miniconda3/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /root/miniconda3/lib/python3.8/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: joblib in /root/miniconda3/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from nltk) (4.61.2)\n",
      "Requirement already satisfied: click in /root/miniconda3/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (1.24.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: pandas in /root/miniconda3/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: scikit-learn in /root/miniconda3/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /root/miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.24.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (4.35.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.61.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: keras in /root/miniconda3/lib/python3.8/site-packages (2.13.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: faiss-gpu in /root/miniconda3/lib/python3.8/site-packages (1.7.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tensorflow in /root/miniconda3/lib/python3.8/site-packages (2.13.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.51.3)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (4.22.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.24.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/lib/python3.8/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/miniconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /root/miniconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /root/miniconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /root/miniconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /root/miniconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /root/miniconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /root/miniconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /root/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /root/miniconda3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install transformers\n",
    "\n",
    "!pip install keras\n",
    "!pip install faiss-gpu\n",
    "\n",
    "!pip install tensorflow\n",
    "import keras\n",
    "import tensorflow\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "# from torch.optim import AdamW\n",
    "from transformers import BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KDTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./df1.csv', nrows=10000)\n",
    "df1['abstract'] = df1['abstract'].astype(str)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 加载Word2Vec模型\n",
    "model_path = \"./GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to autodl-fs/nltk_data2...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 确保这是你的nltk_data目录所在的路径\n",
    "nltk_data_path = 'autodl-fs/nltk_data2'\n",
    "\n",
    "# 添加到NLTK的数据路径\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "\n",
    "nltk.download('punkt', download_dir=nltk_data_path)\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 分词和预处理函数\n",
    "def tokenize_and_process(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    words = [word.lower() for word in words]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "# 对DataFrame中的abstract列进行分词和预处理\n",
    "df1['tokenized_abstract'] = df1['abstract'].apply(tokenize_and_process)\n",
    "\n",
    "# 函数来将单词转换为Word2Vec向量，如果模型中没有该词，则使用UNK向量\n",
    "def word_to_vec(word, model):\n",
    "    return model[word] if word in model.key_to_index else model['UNK']\n",
    "\n",
    "# 函数来将句子的分词列表转换为Word2Vec向量列表\n",
    "def tokens_to_vectors(tokens, model):\n",
    "    return [word_to_vec(token, model) for token in tokens]\n",
    "\n",
    "# 应用函数将tokenized_abstract列的分词列表转换为Word2Vec向量列表\n",
    "df1['word_vectors'] = df1['tokenized_abstract'].apply(lambda tokens: tokens_to_vectors(tokens, word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((8000, 217, 300), (8000, 145))\n",
      "Test set shape: ((2000, 217, 300), (2000, 145))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 找出word_vectors中最长的长度\n",
    "MAX_SEQUENCE_LENGTH = df1['word_vectors'].apply(len).max()\n",
    "UNK_VECTOR = word2vec_model['UNK']  # 获取'UNK'的向量表示\n",
    "# 使用这个长度作为填充或截断的基础\n",
    "def pad_or_truncate_vectors(word_vectors, max_length, unk_vector):\n",
    "    \"\"\"\n",
    "    如果word_vectors长度小于max_length，则用unk_vector填充；\n",
    "    如果word_vectors长度大于max_length，则截断。\n",
    "    \"\"\"\n",
    "    # 获取当前word vectors的长度\n",
    "    sequence_length = len(word_vectors)\n",
    "    \n",
    "    # 如果当前长度小于最大长度，进行填充\n",
    "    if sequence_length < max_length:\n",
    "        padding = [unk_vector] * (max_length - sequence_length)\n",
    "        word_vectors.extend(padding)\n",
    "    # 如果当前长度大于最大长度，进行截断\n",
    "    elif sequence_length > max_length:\n",
    "        word_vectors = word_vectors[:max_length]\n",
    "    \n",
    "    return word_vectors\n",
    "\n",
    "# 应用函数pad_or_truncate_vectors到每一行的word_vectors列\n",
    "df1['padded_word_vectors'] = df1['word_vectors'].apply(\n",
    "    lambda x: pad_or_truncate_vectors(x, MAX_SEQUENCE_LENGTH, UNK_VECTOR))\n",
    "\n",
    "# 检查结果\n",
    "df1['padded_word_vectors'].apply(len)  # 每个向量的长度都应该是MAX_SEQUENCE_LENGTH\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 准备特征：将padded_word_vectors的列表转换为NumPy数组\n",
    "X = np.array(df1['padded_word_vectors'].tolist())\n",
    "\n",
    "# 准备标签：获取所有标签列\n",
    "label_columns = df1.columns.difference(['abstract', 'tokenized_abstract', 'word_vectors', 'padded_word_vectors'])\n",
    "y = df1[label_columns].values\n",
    "\n",
    "# 分割数据集为训练集和测试集，这里使用20%的数据作为测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出分割后的数据集维度，仅用于确认 \n",
    "print(f'Training set shape: {X_train.shape, y_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape, y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: ((8000, 217, 300), (8000, 145))\n",
      "Test set shape: ((2000, 217, 300), (2000, 145))\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set shape: {X_train.shape, y_train.shape}')\n",
    "print(f'Test set shape: {X_test.shape, y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Layer\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_accuracy(y_true, y_pred):\n",
    "    # 预测值大于0.3的被认为是正类\n",
    "    threshold = 0.3\n",
    "    y_pred_thresholded = tf.cast(tf.greater(y_pred, threshold), tf.float32)\n",
    "    \n",
    "    # 计算准确度\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred_thresholded), tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def micro_f1(y_true, y_pred):\n",
    "    # 预测值大于0.3的被认为是正类\n",
    "    y_pred = K.cast(K.greater(y_pred, 0.3), K.floatx())\n",
    "    \n",
    "    # 计算真正例、假正例和假负例\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=0)\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)\n",
    "    \n",
    "    # 计算精确度和召回率\n",
    "    precision = K.sum(true_positives) / (K.sum(predicted_positives) + K.epsilon())\n",
    "    recall = K.sum(true_positives) / (K.sum(possible_positives) + K.epsilon())\n",
    "    \n",
    "    # 计算micro-F1分数\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "# 模型参数\n",
    "max_sequence_length = 217  # 句子的最大长度\n",
    "embedding_dim = 300  # 词嵌入的维度\n",
    "num_labels = 145  # 标签的数量\n",
    "\n",
    "\n",
    "# 模型输入和结构定义\n",
    "input_ = Input(shape=(max_sequence_length, embedding_dim),name='input_')\n",
    "\n",
    "# 可以通过交叉验证调整filters和kernel_size\n",
    "conv = Conv1D(filters=128, kernel_size=5, activation='relu')(input_)\n",
    "gmp = GlobalMaxPooling1D(name='gmp')(conv)\n",
    "dropout = Dropout(0.5)(gmp)\n",
    "# 可以通过交叉验证调整units\n",
    "dense = Dense(128, activation='relu')(dropout)\n",
    "output = Dense(num_labels, activation='sigmoid', name='output')(dense)\n",
    "\n",
    "\n",
    "# 真实标签的输入\n",
    "y_true_input = Input(shape=(num_labels,), name='y_true_input')\n",
    "\n",
    "# 创建模型实例\n",
    "model = Model(inputs=input_, outputs=output)\n",
    "def contrastive_loss_function(y_true, features, tau_prime):\n",
    "    # 计算标签相似度矩阵\n",
    "    label_similarities = tf.matmul(y_true, y_true, transpose_b=True)\n",
    "    \n",
    "    # 动态系数归一化\n",
    "    beta = label_similarities / tf.reduce_sum(label_similarities, axis=1, keepdims=True)\n",
    "    \n",
    "    # 特征标准化\n",
    "    features_norm = tf.nn.l2_normalize(features, axis=1)\n",
    "    \n",
    "    # 计算特征间的成对欧式距离\n",
    "    pairwise_distances = tf.norm(tf.expand_dims(features_norm, 1) - tf.expand_dims(features_norm, 0), axis=2)\n",
    "    \n",
    "    # 对比损失计算\n",
    "    L_con = -beta * tf.math.reduce_logsumexp(-pairwise_distances / tau_prime, axis=1)\n",
    "    \n",
    "    # 将对比损失加和\n",
    "    contrastive_loss = tf.reduce_sum(L_con)\n",
    "    \n",
    "    return contrastive_loss\n",
    "\n",
    "# 自定义层以计算对比损失\n",
    "class ContrastiveLossLayer(Layer):\n",
    "    def __init__(self, gamma=1.0, tau_prime=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma      # 对比损失的权重参数\n",
    "        self.tau_prime = tau_prime  # 温度参数\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y_true, features = inputs\n",
    "        # 计算对比损失，传入温度参数 tau_prime\n",
    "        loss = contrastive_loss_function(y_true, features, self.tau_prime)\n",
    "        # 应用权重 gamma\n",
    "        self.add_loss(loss * self.gamma)\n",
    "        # 返回与 features 形状相同的零张量\n",
    "        return tf.zeros_like(features)\n",
    "\n",
    "\n",
    "# 实例化对比损失层并设置gamma值\n",
    "contrastive_loss_layer = ContrastiveLossLayer(gamma=0.5, name='contrastive_loss')\n",
    "\n",
    "# 获取gmp层的输出用于对比损失计算\n",
    "gmp_output = model.get_layer('gmp').output\n",
    "\n",
    "# 调用对比损失层，并将真实标签和gmp层的输出传入\n",
    "contrastive_loss_layer([y_true_input, gmp_output])\n",
    "model = Model(inputs=[input_, y_true_input], outputs=output)\n",
    "\n",
    "\n",
    "# 编译模型时，只需要指定主输出的损失函数\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[micro_f1, custom_accuracy])\n",
    "\n",
    "# 训练模型时的输入：特征和真实标签\n",
    "model.fit([X_train, y_train],\n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=20,\n",
    "          validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_micro_f1 = model.evaluate([X_test, y_test], y_test)\n",
    "\n",
    "# 打印测试集上的性能\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test micro-F1 score: {test_micro_f1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
